{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final-Model-Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1al7wsk-8Od3ewO7r3IAD82LApJbJnqEy",
      "authorship_tag": "ABX9TyNKfTt1oqhSgnDxVfe4Kk6D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gooran/kasreh-ezafeh/blob/main/Final_Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqFlDg2jBoPt"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFAfmzH-ydfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcb43e0-bcbe-42b6-d077-a2c4d8bfe3f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOI1rkvOLU0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d405a42-0dcb-460e-b2ac-6f490848cff0"
      },
      "source": [
        "!git clone https://github.com/HLTT14/NLP-Assignments.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-Assignments'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 125 (delta 64), reused 12 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (125/125), 22.28 MiB | 8.30 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCtP5yh4Ahv7"
      },
      "source": [
        "!unzip -o -q /content/NLP-Assignments/Assignment2/test.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpm1S4DGBVXi"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV_ezkUUBdOO"
      },
      "source": [
        "# import necessary libraries\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.losses import BinaryCrossentropy"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XY95js1A0kJ"
      },
      "source": [
        "# Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMvyZ2LzA3ru"
      },
      "source": [
        "# Path to the data txt file on disk.\n",
        "data_path = \"/content/test.data\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u19hHwCdDAta"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I84-RWtEDyFf"
      },
      "source": [
        "df = pd.read_fwf(data_path, header = None, names=['word'],skip_blank_lines=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Etlx2NrDvg"
      },
      "source": [
        "df = df.replace(np.nan, '', regex=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_PIvlMElxfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5855861f-f8e2-4eac-a7fe-877ae4dd9984"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>جسته‌وگریخته gen_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>علائم gen_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>و gen_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>نشانه‌هایی gen_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>می‌توان gen_negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        word\n",
              "0  جسته‌وگریخته gen_positive\n",
              "1         علائم gen_negative\n",
              "2             و gen_negative\n",
              "3    نشانه‌هایی gen_negative\n",
              "4       می‌توان gen_negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BwdWGF6UGJB"
      },
      "source": [
        "df['tag'] = df.apply(lambda row: '1' if 'gen_negative' in row.word.split() else '2', axis = 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WViM21hpV9JX"
      },
      "source": [
        "df['word'] = df.apply(lambda row: row.word.replace('gen_negative', '').replace('gen_positive', '').strip(), axis = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Ok7HlR8Z5l"
      },
      "source": [
        "X = [] # store input sequence\n",
        "Y = [] # store output sequence\n",
        "X_sentence = []\n",
        "Y_sentence = []\n",
        "def word2sentence(row):\n",
        "  global X_sentence,Y_sentence,X,Y\n",
        "  if(row.word!=''):\n",
        "    X_sentence.append(row.word)\n",
        "    Y_sentence.append(row.tag)\n",
        "  else:\n",
        "    X.append(X_sentence)\n",
        "    Y.append(Y_sentence)\n",
        "    X_sentence = []\n",
        "    Y_sentence = []"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZF1QeAhUQHd"
      },
      "source": [
        "df.apply(lambda row: word2sentence(row), axis = 1);"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6xbm9IQKstQ"
      },
      "source": [
        "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
        "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rfcl98SKtzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209e39f6-a126-4667-9799-ca661fde7574"
      },
      "source": [
        "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
        "print(\"Vocabulary size: {}\".format(num_words))\n",
        "print(\"Total number of tags: {}\".format(num_tags))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of tagged sentences: 6575\n",
            "Vocabulary size: 16487\n",
            "Total number of tags: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbDjKmnZKxB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ac4623-793f-4e9a-852d-1dee03ac0796"
      },
      "source": [
        "# let's look at first data point\n",
        "# this is one data point that will be fed to the RNN\n",
        "print('sample X: ', X[0], '\\n')\n",
        "print('sample Y: ', Y[0], '\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample X:  ['جسته\\u200cوگریخته', 'علائم', 'و', 'نشانه\\u200cهایی', 'می\\u200cتوان', 'یافت', 'از', 'یک', 'ایدئولوژی', 'التقاطی', 'که', 'بر', 'اندیشه\\u200cهای', 'فاشیستی', 'پیراهنی', 'دینی', 'می\\u200cپوشاند', 'و', 'آرزوها', 'و', 'امیال', 'قدرت\\u200cطلبانه', 'را', 'در', 'پس', 'ارزش\\u200cها', 'و', 'آرمان\\u200cهای', 'ملتی', 'دردمند', 'و', 'متعهد', 'پنهان', 'می\\u200cسازد', '.'] \n",
            "\n",
            "sample Y:  ['2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1mxNBZAMVM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373ec486-a84a-484c-975f-4ff3f002953e"
      },
      "source": [
        "# In this many-to-many problem, the length of each input and output sequence must be the same.\n",
        "# Since each word is tagged, it's important to make sure that the length of input sequence equals the output sequence\n",
        "print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
        "print(\"Length of first output sequence : {}\".format(len(Y[0])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of first input sequence  : 35\n",
            "Length of first output sequence : 35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJQUjpUxManC"
      },
      "source": [
        "# Vectorise X and Y\n",
        "Encode X and Y to integer values\n",
        "\n",
        "We'll use the Tokenizer() function from Keras library to encode text sequence to integer sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCo_jh2xK4UE"
      },
      "source": [
        "# loading word_tokenizer\n",
        "with open('/content/drive/MyDrive/word_tokenizer.pickle', 'rb') as handle:\n",
        "    word_tokenizer = pickle.load(handle)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXyfPsS0MehY"
      },
      "source": [
        "# encode X\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)  # use the tokeniser to encode input sequence"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4hmGFQANaFa"
      },
      "source": [
        "# encode Y\n",
        "Y_encoded = Y"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-k8rgpfNdXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73cac06-01ac-473f-a30b-51b0a123bfaf"
      },
      "source": [
        "# look at first encoded data point\n",
        "\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X[0], '\\n')\n",
        "print('Y: ', Y[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_encoded[0], '\\n')\n",
        "print('Y: ', Y_encoded[0], '\\n')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['جسته\\u200cوگریخته', 'علائم', 'و', 'نشانه\\u200cهایی', 'می\\u200cتوان', 'یافت', 'از', 'یک', 'ایدئولوژی', 'التقاطی', 'که', 'بر', 'اندیشه\\u200cهای', 'فاشیستی', 'پیراهنی', 'دینی', 'می\\u200cپوشاند', 'و', 'آرزوها', 'و', 'امیال', 'قدرت\\u200cطلبانه', 'را', 'در', 'پس', 'ارزش\\u200cها', 'و', 'آرمان\\u200cهای', 'ملتی', 'دردمند', 'و', 'متعهد', 'پنهان', 'می\\u200cسازد', '.'] \n",
            "\n",
            "Y:  ['2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [8128, 1, 8324, 201, 419, 6, 13, 10229, 47241, 7, 20, 3172, 38180, 14238, 780, 10519, 1, 14182, 1, 10613, 8, 4, 76, 1760, 1, 4029, 4450, 12273, 1, 3989, 1435, 1290, 2] \n",
            "\n",
            "Y:  ['2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30AIUVRZNocx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbec6f15-4558-4d20-8214-236d67aa4e5d"
      },
      "source": [
        "# make sure that each sequence of input and output is same length\n",
        "\n",
        "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_encoded, Y_encoded)]\n",
        "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2664 sentences have disparate input-output lengths.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOeKRtn4Nur6"
      },
      "source": [
        "## Pad sequences\n",
        "The next step after encoding the data is to define the sequence lengths. As of now, the sentences present in the data are of various lengths. We need to either pad short sentences or truncate long sentences to a fixed length. This fixed length, however, is a hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVuc9nSbN04B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af42d92-1a10-4c0c-aeb0-ab4aa7ab4511"
      },
      "source": [
        "# check length of longest sentence\n",
        "lengths = [len(seq) for seq in X_encoded]\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of longest sentence: 1225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYlnqGXMOEu5"
      },
      "source": [
        "# Pad each sequence to MAX_SEQ_LENGTH using KERAS' pad_sequences() function. \n",
        "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
        "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
        "\n",
        "# Truncation and padding can either be 'pre' or 'post'. \n",
        "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
        "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
        "\n",
        "MAX_SEQ_LENGTH = 100  # sequences greater than 100 in length will be truncated\n",
        "\n",
        "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
        "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTTIopW-OH86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74394a6-5e0a-4502-a907-14b0a6a82364"
      },
      "source": [
        "# print the first sequence\n",
        "print(X_padded[0], \"\\n\"*3)\n",
        "print(Y_padded[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0  8128     1  8324   201   419\n",
            "     6    13 10229 47241     7    20  3172 38180 14238   780 10519     1\n",
            " 14182     1 10613     8     4    76  1760     1  4029  4450 12273     1\n",
            "  3989  1435  1290     2] \n",
            "\n",
            "\n",
            "\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 1 1 1 1 1 2\n",
            " 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iJUxDSFOOXS"
      },
      "source": [
        "RNN will learn the zero to zero mapping while training. So we don't need to worry about the padded zeroes. Please note that zero is not reserved for any word or tag, it's only reserved for padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2aYIfyrOQER"
      },
      "source": [
        "# assign padded sequences to X and Y\n",
        "X_test, Y_test = X_padded, Y_padded"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttFRl6h_U9Dt"
      },
      "source": [
        "## Use one-hot encoding for output sequences (Y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y4RVQjKU_wL"
      },
      "source": [
        "# use Keras' to_categorical function to one-hot encode Y\n",
        "Y_test = to_categorical(Y_test, num_classes=3)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLQURVkeVGH7",
        "outputId": "284d8043-5c2c-44d7-bcb2-93a50e52a629"
      },
      "source": [
        "# print Y_test of the first output sequqnce\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6575, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWMQ5nTGf3li"
      },
      "source": [
        "## Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm9fuT1I6tud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24397f2b-9da1-4975-a3c3-4b5211b93c4d"
      },
      "source": [
        "final_model = keras.models.load_model('/content/drive/MyDrive/final_model.h5')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB2yMlDngCPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604c53ac-129f-4438-81b6-db095d3e439d"
      },
      "source": [
        "# check summary of model\n",
        "final_model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 200)          11663200  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100, 128)          135680    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 100, 40)           5160      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 100, 3)            123       \n",
            "=================================================================\n",
            "Total params: 11,804,163\n",
            "Trainable params: 135,803\n",
            "Non-trainable params: 11,668,360\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaFp1WweupBr"
      },
      "source": [
        "final_model.compile(loss=BinaryCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=['acc', keras.metrics.Precision(), keras.metrics.Recall()])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyoHPStKSmVy"
      },
      "source": [
        "# Final Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm867oc0SmVz",
        "outputId": "227a65a7-518c-4009-e82b-a080c20e7616"
      },
      "source": [
        "loss, accuracy, precision, recall = final_model.evaluate(X_test, Y_test, verbose = 1)\n",
        "# Calculate f1_score\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print(\"Loss: {0},\\nAccuracy: {1},\\nPrecision: {2},\\nRecall: {3},\\nf1_score: {4}\".format(loss, accuracy, precision, recall,f1_score))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "206/206 [==============================] - 12s 20ms/step - loss: 0.1040 - acc: 0.9652 - precision: 0.9664 - recall: 0.9639\n",
            "Loss: 0.1040399819612503,\n",
            "Accuracy: 0.9652349948883057,\n",
            "Precision: 0.9663771390914917,\n",
            "Recall: 0.9638844132423401,\n",
            "f1_score: 0.9651291666228229\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}