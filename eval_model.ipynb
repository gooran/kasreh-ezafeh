{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eval_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1al7wsk-8Od3ewO7r3IAD82LApJbJnqEy",
      "authorship_tag": "ABX9TyMDg76x6xWfTBfNbbx9XIYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gooran/kasreh-ezafeh/blob/main/eval_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqFlDg2jBoPt"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFAfmzH-ydfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4dfedab-8711-4c3a-ff21-d166cd7f38ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOI1rkvOLU0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fa68da-11df-4480-95ec-ad17bb5ebfae"
      },
      "source": [
        "!git clone https://github.com/HLTT14/NLP-Assignments.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP-Assignments'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 95 (delta 47), reused 12 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (95/95), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCtP5yh4Ahv7"
      },
      "source": [
        "!unzip -o -q /content/NLP-Assignments/Assignment2/train.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpm1S4DGBVXi"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV_ezkUUBdOO"
      },
      "source": [
        "# import necessary libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.losses import BinaryCrossentropy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XY95js1A0kJ"
      },
      "source": [
        "# Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMvyZ2LzA3ru"
      },
      "source": [
        "# Path to the data txt file on disk.\n",
        "data_path = \"/content/train.data\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u19hHwCdDAta"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I84-RWtEDyFf"
      },
      "source": [
        "df = pd.read_fwf(data_path, header = None, names=['word'],skip_blank_lines=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Etlx2NrDvg"
      },
      "source": [
        "df = df.replace(np.nan, '', regex=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_PIvlMElxfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a1cb7e26-777e-4ee6-8671-2697b6ccd2e9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td># gen_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>منبع gen_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>: gen_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>) gen_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>مجلة gen_positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                word\n",
              "0     # gen_negative\n",
              "1  منبع gen_negative\n",
              "2     : gen_negative\n",
              "3     ) gen_negative\n",
              "4  مجلة gen_positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BwdWGF6UGJB"
      },
      "source": [
        "df['tag'] = df.apply(lambda row: '1' if 'gen_negative' in row.word.split() else '2', axis = 1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WViM21hpV9JX"
      },
      "source": [
        "df['word'] = df.apply(lambda row: row.word.replace('gen_negative', '').replace('gen_positive', '').strip(), axis = 1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Ok7HlR8Z5l"
      },
      "source": [
        "X = [] # store input sequence\n",
        "Y = [] # store output sequence\n",
        "X_sentence = []\n",
        "Y_sentence = []\n",
        "for index, row in df.iterrows():\n",
        "  if(row.word!=''):\n",
        "    X_sentence.append(row.word)\n",
        "    Y_sentence.append(row.tag)\n",
        "  else:\n",
        "    X.append(X_sentence)\n",
        "    Y.append(Y_sentence)\n",
        "    X_sentence = []\n",
        "    Y_sentence = []"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6xbm9IQKstQ"
      },
      "source": [
        "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
        "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rfcl98SKtzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7849b422-04a5-4d18-d102-7bdca8f5ef72"
      },
      "source": [
        "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
        "print(\"Vocabulary size: {}\".format(num_words))\n",
        "print(\"Total number of tags: {}\".format(num_tags))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of tagged sentences: 70103\n",
            "Vocabulary size: 58315\n",
            "Total number of tags: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbDjKmnZKxB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0809dddb-7946-4b04-a9b4-f61af4509027"
      },
      "source": [
        "# let's look at first data point\n",
        "# this is one data point that will be fed to the RNN\n",
        "print('sample X: ', X[0], '\\n')\n",
        "print('sample Y: ', Y[0], '\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample X:  ['#', 'منبع', ':', ')', 'مجلة', 'سروش', 'هفتگی', '،', 'مصاحبه', 'با', 'رئیس', 'دفتر', 'الجزیره', 'در', 'تهران', '،', 'یک', 'هزار', 'و', 'سیصد', 'و', 'هشتاد', '(', '#', '#', 'الجزیره', 'هیچ', 'ارتباط', 'خاصی', 'با', 'طالبان', 'ندارد', '.'] \n",
            "\n",
            "sample Y:  ['1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1mxNBZAMVM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9b7d75-7db1-44cc-a7ff-3505e66fcc18"
      },
      "source": [
        "# In this many-to-many problem, the length of each input and output sequence must be the same.\n",
        "# Since each word is tagged, it's important to make sure that the length of input sequence equals the output sequence\n",
        "print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
        "print(\"Length of first output sequence : {}\".format(len(Y[0])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of first input sequence  : 33\n",
            "Length of first output sequence : 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJQUjpUxManC"
      },
      "source": [
        "# Vectorise X and Y\n",
        "Encode X and Y to integer values\n",
        "\n",
        "We'll use the Tokenizer() function from Keras library to encode text sequence to integer sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXyfPsS0MehY"
      },
      "source": [
        "# encode X\n",
        "\n",
        "word_tokenizer = Tokenizer()                      # instantiate tokeniser\n",
        "word_tokenizer.fit_on_texts(X)                    # fit tokeniser on data\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)  # use the tokeniser to encode input sequence"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4hmGFQANaFa"
      },
      "source": [
        "# encode Y\n",
        "\n",
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(Y)\n",
        "Y_encoded = tag_tokenizer.texts_to_sequences(Y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-k8rgpfNdXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86810666-51f1-4425-b76a-6eec0a6dafaf"
      },
      "source": [
        "# look at first encoded data point\n",
        "\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X[0], '\\n')\n",
        "print('Y: ', Y[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_encoded[0], '\\n')\n",
        "print('Y: ', Y_encoded[0], '\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['#', 'منبع', ':', ')', 'مجلة', 'سروش', 'هفتگی', '،', 'مصاحبه', 'با', 'رئیس', 'دفتر', 'الجزیره', 'در', 'تهران', '،', 'یک', 'هزار', 'و', 'سیصد', 'و', 'هشتاد', '(', '#', '#', 'الجزیره', 'هیچ', 'ارتباط', 'خاصی', 'با', 'طالبان', 'ندارد', '.'] \n",
            "\n",
            "Y:  ['1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [30, 668, 12, 43, 1333, 1543, 1585, 3, 1607, 11, 171, 526, 1740, 4, 88, 3, 13, 33, 1, 140, 1, 179, 39, 30, 30, 1740, 92, 413, 640, 11, 4360, 243, 2] \n",
            "\n",
            "Y:  [1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30AIUVRZNocx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986fd4c6-7be8-46fc-89b0-ef31eaceb7be"
      },
      "source": [
        "# make sure that each sequence of input and output is same length\n",
        "\n",
        "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_encoded, Y_encoded)]\n",
        "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 sentences have disparate input-output lengths.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOeKRtn4Nur6"
      },
      "source": [
        "## Pad sequences\n",
        "The next step after encoding the data is to define the sequence lengths. As of now, the sentences present in the data are of various lengths. We need to either pad short sentences or truncate long sentences to a fixed length. This fixed length, however, is a hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVuc9nSbN04B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa15e22c-d4ad-4d8f-f35f-2223dc3e119f"
      },
      "source": [
        "# check length of longest sentence\n",
        "lengths = [len(seq) for seq in X_encoded]\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of longest sentence: 1146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8FperICN7sJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "592f76ed-408b-4fe4-d10e-055d59b34ab6"
      },
      "source": [
        "sns.boxplot(lengths)\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYlnqGXMOEu5"
      },
      "source": [
        "# Pad each sequence to MAX_SEQ_LENGTH using KERAS' pad_sequences() function. \n",
        "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
        "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
        "\n",
        "# Truncation and padding can either be 'pre' or 'post'. \n",
        "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
        "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
        "\n",
        "MAX_SEQ_LENGTH = 100  # sequences greater than 100 in length will be truncated\n",
        "\n",
        "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
        "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTTIopW-OH86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f522b7f3-890e-4d92-af5b-254f1e52d0aa"
      },
      "source": [
        "# print the first sequence\n",
        "print(X_padded[0], \"\\n\"*3)\n",
        "print(Y_padded[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0   30  668   12\n",
            "   43 1333 1543 1585    3 1607   11  171  526 1740    4   88    3   13\n",
            "   33    1  140    1  179   39   30   30 1740   92  413  640   11 4360\n",
            "  243    2] \n",
            "\n",
            "\n",
            "\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 2 2 1\n",
            " 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iJUxDSFOOXS"
      },
      "source": [
        "RNN will learn the zero to zero mapping while training. So we don't need to worry about the padded zeroes. Please note that zero is not reserved for any word or tag, it's only reserved for padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2aYIfyrOQER"
      },
      "source": [
        "# assign padded sequences to X and Y\n",
        "X, Y = X_padded, Y_padded"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWMQ5nTGf3li"
      },
      "source": [
        "## Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm9fuT1I6tud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f18071-1823-4fe2-9c12-193cd97ce5cc"
      },
      "source": [
        "final_model = keras.models.load_model('/content/drive/MyDrive/final_model.h5')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB2yMlDngCPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59b84ca-261e-450c-f37c-ac79d42ce07d"
      },
      "source": [
        "# check summary of model\n",
        "final_model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 200)          11663200  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 100, 128)          135680    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 100, 40)           5160      \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 100, 1)            41        \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 100, 1)            2         \n",
            "=================================================================\n",
            "Total params: 11,804,083\n",
            "Trainable params: 135,682\n",
            "Non-trainable params: 11,668,401\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaFp1WweupBr"
      },
      "source": [
        "final_model.compile(loss=BinaryCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=[keras.metrics.Precision(), keras.metrics.Recall()])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnycGEZGLsQs"
      },
      "source": [
        "## Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RbPDx3Txjhf"
      },
      "source": [
        "# split entire data into training and testing sets\n",
        "TEST_SIZE = 0.15\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=4)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWNcMdtVxjhg"
      },
      "source": [
        "# split training data into training and validation sets\n",
        "VALID_SIZE = 0.15\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=VALID_SIZE, random_state=4)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyoHPStKSmVy"
      },
      "source": [
        "# Final Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm867oc0SmVz",
        "outputId": "056dc3c1-82c9-4016-a567-511e32bc3749"
      },
      "source": [
        "loss, precision, recall = final_model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print(\"Loss: {0},\\nPrecision: {1},\\nRecall: {2}\".format(loss, precision, recall))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "329/329 [==============================] - 11s 8ms/step - loss: 0.0644 - precision: 1.0000 - recall: 0.9995\n",
            "Loss: 0.0643812045454979,\n",
            "Precision: 1.0,\n",
            "Recall: 0.9994803667068481\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}